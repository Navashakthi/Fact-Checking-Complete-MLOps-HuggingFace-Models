{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Navashakthi/Fact-Checking-Complete-MLOps-using-HuggingFace-Models/blob/main/Execution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Model Selection**\n",
        "To decide on the best model to use, we can evaluate each based on a few critical factors such as Model Architecture, Model Size & Computational Requirements, Performance metrics, and Inference Speed.\n",
        "\n",
        "Here we take performance metrics such as accuracy, F1-score, and Loss of each model to get the best model."
      ],
      "metadata": {
        "id": "m53mxjriNZh4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rSAvGFfZ9Hd",
        "outputId": "b55012b3-42c1-48eb-b641-d0837ec50c9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Model: Model C\n",
            "Composite Score: 0.8172\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Metrics for three models\n",
        "data = {\n",
        "    'Model': ['Model A', 'Model B', 'Model C'],\n",
        "    'Accuracy': [0.6285, 0.797, 0.933],\n",
        "    'Loss': [1.1227, 0.5858, 0.3454],\n",
        "    'F1 Score': [0.6545, 0.9234, 0.9154],\n",
        "    'Micro F1': [0.0, 0.8122, 0.8130],\n",
        "    'Macro F1': [0.0, 0.6830, 0.6874]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "weights = {\n",
        "    'Accuracy': 0.2,\n",
        "    'Loss': 0.2,\n",
        "    'F1 Score': 0.3,\n",
        "    'Micro F1': 0.15,\n",
        "    'Macro F1': 0.15\n",
        "}\n",
        "\n",
        "\n",
        "# Calculate composite score\n",
        "def calculate_score(row):\n",
        "    return (\n",
        "        row['Accuracy'] * weights['Accuracy'] +\n",
        "        (1 - row['Loss']) * weights['Loss'] +  # Minimize loss\n",
        "        row['F1 Score'] * weights['F1 Score'] +\n",
        "        row['Micro F1'] * weights['Micro F1'] +\n",
        "        row['Macro F1'] * weights['Macro F1']\n",
        "    )\n",
        "\n",
        "df['Composite Score'] = df.apply(calculate_score, axis=1)\n",
        "\n",
        "# Rank models\n",
        "best_model = df.loc[df['Composite Score'].idxmax()]\n",
        "print(\"Best Model:\", best_model['Model'])\n",
        "print(\"Composite Score:\", best_model['Composite Score'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbJ0AiZ7iHaR",
        "outputId": "0fe3fea7-34c2-45b0-e512-76a91087c771"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from -r /content/requirements.txt (line 1)) (4.44.2)\n",
            "Collecting datasets (from -r /content/requirements.txt (line 2))\n",
            "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from -r /content/requirements.txt (line 3)) (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r /content/requirements.txt (line 4)) (1.26.4)\n",
            "Collecting fastapi (from -r /content/requirements.txt (line 5))\n",
            "  Downloading fastapi-0.115.4-py3-none-any.whl.metadata (27 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r /content/requirements.txt (line 8)) (2.5.0+cu121)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from -r /content/requirements.txt (line 9)) (2.9.2)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (from -r /content/requirements.txt (line 10)) (7.4.4)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from -r /content/requirements.txt (line 11)) (0.27.2)\n",
            "Collecting gradio (from -r /content/requirements.txt (line 12))\n",
            "  Downloading gradio-5.5.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (from -r /content/requirements.txt (line 13)) (1.6.0)\n",
            "Collecting uvicorn[standard] (from -r /content/requirements.txt (line 6))\n",
            "  Downloading uvicorn-0.32.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers->-r /content/requirements.txt (line 1)) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers->-r /content/requirements.txt (line 1)) (0.24.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers->-r /content/requirements.txt (line 1)) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->-r /content/requirements.txt (line 1)) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->-r /content/requirements.txt (line 1)) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->-r /content/requirements.txt (line 1)) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->-r /content/requirements.txt (line 1)) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->-r /content/requirements.txt (line 1)) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers->-r /content/requirements.txt (line 1)) (4.66.6)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r /content/requirements.txt (line 2)) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets->-r /content/requirements.txt (line 2))\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting xxhash (from datasets->-r /content/requirements.txt (line 2))\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets->-r /content/requirements.txt (line 2))\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets->-r /content/requirements.txt (line 2))\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->-r /content/requirements.txt (line 2)) (3.10.10)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->-r /content/requirements.txt (line 3)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r /content/requirements.txt (line 3)) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->-r /content/requirements.txt (line 3)) (2024.2)\n",
            "Collecting starlette<0.42.0,>=0.40.0 (from fastapi->-r /content/requirements.txt (line 5))\n",
            "  Downloading starlette-0.41.2-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from fastapi->-r /content/requirements.txt (line 5)) (4.12.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]->-r /content/requirements.txt (line 6)) (8.1.7)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]->-r /content/requirements.txt (line 6)) (0.14.0)\n",
            "Collecting httptools>=0.5.0 (from uvicorn[standard]->-r /content/requirements.txt (line 6))\n",
            "  Downloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting python-dotenv>=0.13 (from uvicorn[standard]->-r /content/requirements.txt (line 6))\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]->-r /content/requirements.txt (line 6))\n",
            "  Downloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]->-r /content/requirements.txt (line 6))\n",
            "  Downloading watchfiles-0.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting websockets>=10.4 (from uvicorn[standard]->-r /content/requirements.txt (line 6))\n",
            "  Downloading websockets-13.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r /content/requirements.txt (line 8)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r /content/requirements.txt (line 8)) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->-r /content/requirements.txt (line 8)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->-r /content/requirements.txt (line 8)) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->-r /content/requirements.txt (line 9)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic->-r /content/requirements.txt (line 9)) (2.23.4)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest->-r /content/requirements.txt (line 10)) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest->-r /content/requirements.txt (line 10)) (1.5.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest->-r /content/requirements.txt (line 10)) (1.2.2)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest->-r /content/requirements.txt (line 10)) (2.0.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->-r /content/requirements.txt (line 11)) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->-r /content/requirements.txt (line 11)) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->-r /content/requirements.txt (line 11)) (1.0.6)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->-r /content/requirements.txt (line 11)) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->-r /content/requirements.txt (line 11)) (1.3.1)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio->-r /content/requirements.txt (line 12))\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting ffmpy (from gradio->-r /content/requirements.txt (line 12))\n",
            "  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting gradio-client==1.4.2 (from gradio->-r /content/requirements.txt (line 12))\n",
            "  Downloading gradio_client-1.4.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting huggingface-hub<1.0,>=0.23.2 (from transformers->-r /content/requirements.txt (line 1))\n",
            "  Downloading huggingface_hub-0.26.2-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting markupsafe~=2.0 (from gradio->-r /content/requirements.txt (line 12))\n",
            "  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r /content/requirements.txt (line 12)) (3.10.10)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r /content/requirements.txt (line 12)) (10.4.0)\n",
            "Collecting pydub (from gradio->-r /content/requirements.txt (line 12))\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart==0.0.12 (from gradio->-r /content/requirements.txt (line 12))\n",
            "  Downloading python_multipart-0.0.12-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting ruff>=0.2.2 (from gradio->-r /content/requirements.txt (line 12))\n",
            "  Downloading ruff-0.7.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<1.0,>=0.1.1 (from gradio->-r /content/requirements.txt (line 12))\n",
            "  Downloading safehttpx-0.1.1-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio->-r /content/requirements.txt (line 12))\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio->-r /content/requirements.txt (line 12))\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio->-r /content/requirements.txt (line 12)) (0.12.5)\n",
            "Collecting websockets>=10.4 (from uvicorn[standard]->-r /content/requirements.txt (line 6))\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r /content/requirements.txt (line 2)) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r /content/requirements.txt (line 2)) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r /content/requirements.txt (line 2)) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r /content/requirements.txt (line 2)) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r /content/requirements.txt (line 2)) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r /content/requirements.txt (line 2)) (1.17.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r /content/requirements.txt (line 2)) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->-r /content/requirements.txt (line 3)) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->-r /content/requirements.txt (line 1)) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->-r /content/requirements.txt (line 1)) (2.2.3)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio->-r /content/requirements.txt (line 12)) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio->-r /content/requirements.txt (line 12)) (13.9.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio->-r /content/requirements.txt (line 12)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio->-r /content/requirements.txt (line 12)) (2.18.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets->-r /content/requirements.txt (line 2)) (0.2.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio->-r /content/requirements.txt (line 12)) (0.1.2)\n",
            "Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.115.4-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m94.7/94.7 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio-5.5.0-py3-none-any.whl (56.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.7/56.7 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.4.2-py3-none-any.whl (319 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m319.8/319.8 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.12-py3-none-any.whl (23 kB)\n",
            "Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (442 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m442.1/442.1 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.26.2-py3-none-any.whl (447 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m447.5/447.5 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading ruff-0.7.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.1-py3-none-any.whl (8.4 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.41.2-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m73.3/73.3 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.32.0-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m68.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-0.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (425 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m425.7/425.7 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydub, xxhash, websockets, uvloop, uvicorn, tomlkit, semantic-version, ruff, python-multipart, python-dotenv, markupsafe, httptools, fsspec, ffmpy, dill, aiofiles, watchfiles, starlette, multiprocess, huggingface-hub, safehttpx, gradio-client, fastapi, gradio, datasets\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.24.7\n",
            "    Uninstalling huggingface-hub-0.24.7:\n",
            "      Successfully uninstalled huggingface-hub-0.24.7\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiofiles-23.2.1 datasets-3.1.0 dill-0.3.8 fastapi-0.115.4 ffmpy-0.4.0 fsspec-2024.9.0 gradio-5.5.0 gradio-client-1.4.2 httptools-0.6.4 huggingface-hub-0.26.2 markupsafe-2.1.5 multiprocess-0.70.16 pydub-0.25.1 python-dotenv-1.0.1 python-multipart-0.0.12 ruff-0.7.2 safehttpx-0.1.1 semantic-version-2.10.0 starlette-0.41.2 tomlkit-0.12.0 uvicorn-0.32.0 uvloop-0.21.0 watchfiles-0.24.0 websockets-12.0 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -r /content/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sp-HWw14iaw6",
        "outputId": "70db8fc7-c9ff-44ee-98fa-b10830e33855"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading the PUBHEALTH dataset...\n",
            "README.md: 100% 8.61k/8.61k [00:00<00:00, 31.0MB/s]\n",
            "health_fact.py: 100% 7.08k/7.08k [00:00<00:00, 27.6MB/s]\n",
            "Downloading data: 100% 24.9M/24.9M [00:00<00:00, 76.7MB/s]\n",
            "Generating train split: 100% 9832/9832 [00:03<00:00, 2783.62 examples/s]\n",
            "Generating test split: 100% 1235/1235 [00:00<00:00, 1567.52 examples/s]\n",
            "Generating validation split: 100% 1225/1225 [00:00<00:00, 1834.96 examples/s]\n",
            "Saving the dataset to data...\n",
            "Creating json from Arrow format: 100% 10/10 [00:02<00:00,  4.83ba/s]\n",
            "Saved train split to data/pubhealth_train.jsonl\n",
            "Creating json from Arrow format: 100% 2/2 [00:00<00:00,  7.75ba/s]\n",
            "Saved test split to data/pubhealth_test.jsonl\n",
            "Creating json from Arrow format: 100% 2/2 [00:00<00:00, 11.43ba/s]\n",
            "Saved validation split to data/pubhealth_validation.jsonl\n",
            "Download and save complete.\n"
          ]
        }
      ],
      "source": [
        "!python /content/ingest.py --save_dir data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhB9z3eejZUc",
        "outputId": "06d9911f-0da0-4317-a982-0709c89f79a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "Loading the PUBHEALTH dataset...\n",
            "Processing train split...\n",
            "Train data saved to processed_data/pubhealth_train.csv\n",
            "Processing validation split...\n",
            "Validation data saved to processed_data/pubhealth_validation.csv\n",
            "Processing test split...\n",
            "Test data saved to processed_data/pubhealth_test.csv\n"
          ]
        }
      ],
      "source": [
        "!python /content/prepare.py --data_dir data --output_dir processed_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LS0bCqg5wFBh",
        "outputId": "0e5da484-c295-47d8-9d8d-75a46799efe4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n",
            "\r0it [00:00, ?it/s]\r0it [00:00, ?it/s]\n",
            "2024-11-07 13:55:48.343786: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-11-07 13:55:48.382279: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-11-07 13:55:48.392784: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-11-07 13:55:48.417972: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-11-07 13:55:50.494653: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "tokenizer_config.json: 100% 333/333 [00:00<00:00, 1.44MB/s]\n",
            "vocab.txt: 100% 232k/232k [00:00<00:00, 1.40MB/s]\n",
            "tokenizer.json: 100% 466k/466k [00:00<00:00, 5.69MB/s]\n",
            "special_tokens_map.json: 100% 112/112 [00:00<00:00, 685kB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "config.json: 100% 807/807 [00:00<00:00, 4.42MB/s]\n",
            "pytorch_model.bin: 100% 268M/268M [00:01<00:00, 212MB/s]\n",
            "Map: 100% 9800/9800 [00:02<00:00, 3348.70 examples/s]\n",
            "Map: 100% 2451/2451 [00:00<00:00, 4052.86 examples/s]\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Use an existing W&B account'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20241107_135712-v9n7puj9\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m./results\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/navashakthi-capgemini/huggingface\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ğŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/navashakthi-capgemini/huggingface/runs/v9n7puj9\u001b[0m\n",
            "{'loss': 0.898, 'grad_norm': 6.267813682556152, 'learning_rate': 3.68678629690049e-06, 'epoch': 0.82}\n",
            "100% 613/613 [06:56<00:00,  1.72it/s]\n",
            "  0% 0/154 [00:00<?, ?it/s]\u001b[A\n",
            "  1% 2/154 [00:00<00:22,  6.91it/s]\u001b[A\n",
            "  2% 3/154 [00:00<00:27,  5.42it/s]\u001b[A\n",
            "  3% 4/154 [00:00<00:30,  4.88it/s]\u001b[A\n",
            "  3% 5/154 [00:01<00:32,  4.63it/s]\u001b[A\n",
            "  4% 6/154 [00:01<00:33,  4.44it/s]\u001b[A\n",
            "  5% 7/154 [00:01<00:33,  4.33it/s]\u001b[A\n",
            "  5% 8/154 [00:01<00:34,  4.27it/s]\u001b[A\n",
            "  6% 9/154 [00:01<00:34,  4.23it/s]\u001b[A\n",
            "  6% 10/154 [00:02<00:34,  4.20it/s]\u001b[A\n",
            "  7% 11/154 [00:02<00:34,  4.17it/s]\u001b[A\n",
            "  8% 12/154 [00:02<00:34,  4.17it/s]\u001b[A\n",
            "  8% 13/154 [00:02<00:33,  4.16it/s]\u001b[A\n",
            "  9% 14/154 [00:03<00:33,  4.17it/s]\u001b[A\n",
            " 10% 15/154 [00:03<00:33,  4.16it/s]\u001b[A\n",
            " 10% 16/154 [00:03<00:33,  4.14it/s]\u001b[A\n",
            " 11% 17/154 [00:03<00:33,  4.14it/s]\u001b[A\n",
            " 12% 18/154 [00:04<00:32,  4.13it/s]\u001b[A\n",
            " 12% 19/154 [00:04<00:32,  4.16it/s]\u001b[A\n",
            " 13% 20/154 [00:04<00:32,  4.14it/s]\u001b[A\n",
            " 14% 21/154 [00:04<00:32,  4.15it/s]\u001b[A\n",
            " 14% 22/154 [00:05<00:31,  4.14it/s]\u001b[A\n",
            " 15% 23/154 [00:05<00:31,  4.13it/s]\u001b[A\n",
            " 16% 24/154 [00:05<00:31,  4.12it/s]\u001b[A\n",
            " 16% 25/154 [00:05<00:31,  4.12it/s]\u001b[A\n",
            " 17% 26/154 [00:06<00:31,  4.12it/s]\u001b[A\n",
            " 18% 27/154 [00:06<00:30,  4.11it/s]\u001b[A\n",
            " 18% 28/154 [00:06<00:30,  4.12it/s]\u001b[A\n",
            " 19% 29/154 [00:06<00:30,  4.12it/s]\u001b[A\n",
            " 19% 30/154 [00:07<00:30,  4.12it/s]\u001b[A\n",
            " 20% 31/154 [00:07<00:29,  4.11it/s]\u001b[A\n",
            " 21% 32/154 [00:07<00:29,  4.11it/s]\u001b[A\n",
            " 21% 33/154 [00:07<00:29,  4.11it/s]\u001b[A\n",
            " 22% 34/154 [00:08<00:29,  4.11it/s]\u001b[A\n",
            " 23% 35/154 [00:08<00:28,  4.11it/s]\u001b[A\n",
            " 23% 36/154 [00:08<00:28,  4.11it/s]\u001b[A\n",
            " 24% 37/154 [00:08<00:28,  4.09it/s]\u001b[A\n",
            " 25% 38/154 [00:09<00:28,  4.11it/s]\u001b[A\n",
            " 25% 39/154 [00:09<00:27,  4.11it/s]\u001b[A\n",
            " 26% 40/154 [00:09<00:27,  4.10it/s]\u001b[A\n",
            " 27% 41/154 [00:09<00:27,  4.10it/s]\u001b[A\n",
            " 27% 42/154 [00:09<00:27,  4.09it/s]\u001b[A\n",
            " 28% 43/154 [00:10<00:26,  4.11it/s]\u001b[A\n",
            " 29% 44/154 [00:10<00:26,  4.12it/s]\u001b[A\n",
            " 29% 45/154 [00:10<00:26,  4.11it/s]\u001b[A\n",
            " 30% 46/154 [00:10<00:26,  4.09it/s]\u001b[A\n",
            " 31% 47/154 [00:11<00:26,  4.11it/s]\u001b[A\n",
            " 31% 48/154 [00:11<00:25,  4.11it/s]\u001b[A\n",
            " 32% 49/154 [00:11<00:25,  4.12it/s]\u001b[A\n",
            " 32% 50/154 [00:11<00:25,  4.07it/s]\u001b[A\n",
            " 33% 51/154 [00:12<00:24,  4.13it/s]\u001b[A\n",
            " 34% 52/154 [00:12<00:24,  4.12it/s]\u001b[A\n",
            " 34% 53/154 [00:12<00:24,  4.12it/s]\u001b[A\n",
            " 35% 54/154 [00:12<00:24,  4.10it/s]\u001b[A\n",
            " 36% 55/154 [00:13<00:24,  4.12it/s]\u001b[A\n",
            " 36% 56/154 [00:13<00:23,  4.13it/s]\u001b[A\n",
            " 37% 57/154 [00:13<00:23,  4.13it/s]\u001b[A\n",
            " 38% 58/154 [00:13<00:23,  4.12it/s]\u001b[A\n",
            " 38% 59/154 [00:14<00:23,  4.12it/s]\u001b[A\n",
            " 39% 60/154 [00:14<00:22,  4.12it/s]\u001b[A\n",
            " 40% 61/154 [00:14<00:22,  4.12it/s]\u001b[A\n",
            " 40% 62/154 [00:14<00:22,  4.10it/s]\u001b[A\n",
            " 41% 63/154 [00:15<00:22,  4.11it/s]\u001b[A\n",
            " 42% 64/154 [00:15<00:21,  4.11it/s]\u001b[A\n",
            " 42% 65/154 [00:15<00:21,  4.12it/s]\u001b[A\n",
            " 43% 66/154 [00:15<00:21,  4.12it/s]\u001b[A\n",
            " 44% 67/154 [00:16<00:21,  4.11it/s]\u001b[A\n",
            " 44% 68/154 [00:16<00:20,  4.12it/s]\u001b[A\n",
            " 45% 69/154 [00:16<00:20,  4.11it/s]\u001b[A\n",
            " 45% 70/154 [00:16<00:20,  4.11it/s]\u001b[A\n",
            " 46% 71/154 [00:17<00:20,  4.10it/s]\u001b[A\n",
            " 47% 72/154 [00:17<00:19,  4.11it/s]\u001b[A\n",
            " 47% 73/154 [00:17<00:19,  4.11it/s]\u001b[A\n",
            " 48% 74/154 [00:17<00:19,  4.12it/s]\u001b[A\n",
            " 49% 75/154 [00:18<00:19,  4.11it/s]\u001b[A\n",
            " 49% 76/154 [00:18<00:18,  4.11it/s]\u001b[A\n",
            " 50% 77/154 [00:18<00:18,  4.12it/s]\u001b[A\n",
            " 51% 78/154 [00:18<00:18,  4.12it/s]\u001b[A\n",
            " 51% 79/154 [00:18<00:18,  4.11it/s]\u001b[A\n",
            " 52% 80/154 [00:19<00:17,  4.11it/s]\u001b[A\n",
            " 53% 81/154 [00:19<00:17,  4.11it/s]\u001b[A\n",
            " 53% 82/154 [00:19<00:17,  4.11it/s]\u001b[A\n",
            " 54% 83/154 [00:19<00:17,  4.11it/s]\u001b[A\n",
            " 55% 84/154 [00:20<00:17,  4.11it/s]\u001b[A\n",
            " 55% 85/154 [00:20<00:16,  4.11it/s]\u001b[A\n",
            " 56% 86/154 [00:20<00:16,  4.11it/s]\u001b[A\n",
            " 56% 87/154 [00:20<00:16,  4.10it/s]\u001b[A\n",
            " 57% 88/154 [00:21<00:16,  4.09it/s]\u001b[A\n",
            " 58% 89/154 [00:21<00:15,  4.09it/s]\u001b[A\n",
            " 58% 90/154 [00:21<00:15,  4.09it/s]\u001b[A\n",
            " 59% 91/154 [00:21<00:15,  4.09it/s]\u001b[A\n",
            " 60% 92/154 [00:22<00:15,  4.07it/s]\u001b[A\n",
            " 60% 93/154 [00:22<00:14,  4.07it/s]\u001b[A\n",
            " 61% 94/154 [00:22<00:14,  4.09it/s]\u001b[A\n",
            " 62% 95/154 [00:22<00:14,  4.09it/s]\u001b[A\n",
            " 62% 96/154 [00:23<00:14,  4.05it/s]\u001b[A\n",
            " 63% 97/154 [00:23<00:14,  4.05it/s]\u001b[A\n",
            " 64% 98/154 [00:23<00:13,  4.07it/s]\u001b[A\n",
            " 64% 99/154 [00:23<00:13,  4.08it/s]\u001b[A\n",
            " 65% 100/154 [00:24<00:13,  4.09it/s]\u001b[A\n",
            " 66% 101/154 [00:24<00:13,  4.05it/s]\u001b[A\n",
            " 66% 102/154 [00:24<00:12,  4.07it/s]\u001b[A\n",
            " 67% 103/154 [00:24<00:12,  4.04it/s]\u001b[A\n",
            " 68% 104/154 [00:25<00:12,  4.06it/s]\u001b[A\n",
            " 68% 105/154 [00:25<00:12,  4.06it/s]\u001b[A\n",
            " 69% 106/154 [00:25<00:11,  4.05it/s]\u001b[A\n",
            " 69% 107/154 [00:25<00:11,  4.06it/s]\u001b[A\n",
            " 70% 108/154 [00:26<00:11,  4.05it/s]\u001b[A\n",
            " 71% 109/154 [00:26<00:11,  4.05it/s]\u001b[A\n",
            " 71% 110/154 [00:26<00:10,  4.06it/s]\u001b[A\n",
            " 72% 111/154 [00:26<00:10,  4.06it/s]\u001b[A\n",
            " 73% 112/154 [00:27<00:10,  4.03it/s]\u001b[A\n",
            " 73% 113/154 [00:27<00:10,  4.04it/s]\u001b[A\n",
            " 74% 114/154 [00:27<00:09,  4.08it/s]\u001b[A\n",
            " 75% 115/154 [00:27<00:09,  4.07it/s]\u001b[A\n",
            " 75% 116/154 [00:28<00:09,  4.06it/s]\u001b[A\n",
            " 76% 117/154 [00:28<00:09,  4.06it/s]\u001b[A\n",
            " 77% 118/154 [00:28<00:08,  4.05it/s]\u001b[A\n",
            " 77% 119/154 [00:28<00:08,  4.09it/s]\u001b[A\n",
            " 78% 120/154 [00:29<00:08,  4.07it/s]\u001b[A\n",
            " 79% 121/154 [00:29<00:08,  4.06it/s]\u001b[A\n",
            " 79% 122/154 [00:29<00:07,  4.06it/s]\u001b[A\n",
            " 80% 123/154 [00:29<00:07,  4.07it/s]\u001b[A\n",
            " 81% 124/154 [00:30<00:07,  4.08it/s]\u001b[A\n",
            " 81% 125/154 [00:30<00:07,  4.08it/s]\u001b[A\n",
            " 82% 126/154 [00:30<00:06,  4.08it/s]\u001b[A\n",
            " 82% 127/154 [00:30<00:06,  4.08it/s]\u001b[A\n",
            " 83% 128/154 [00:31<00:06,  4.07it/s]\u001b[A\n",
            " 84% 129/154 [00:31<00:06,  4.06it/s]\u001b[A\n",
            " 84% 130/154 [00:31<00:05,  4.08it/s]\u001b[A\n",
            " 85% 131/154 [00:31<00:05,  4.09it/s]\u001b[A\n",
            " 86% 132/154 [00:31<00:05,  4.09it/s]\u001b[A\n",
            " 86% 133/154 [00:32<00:05,  4.09it/s]\u001b[A\n",
            " 87% 134/154 [00:32<00:04,  4.09it/s]\u001b[A\n",
            " 88% 135/154 [00:32<00:04,  4.10it/s]\u001b[A\n",
            " 88% 136/154 [00:32<00:04,  4.10it/s]\u001b[A\n",
            " 89% 137/154 [00:33<00:04,  4.09it/s]\u001b[A\n",
            " 90% 138/154 [00:33<00:03,  4.07it/s]\u001b[A\n",
            " 90% 139/154 [00:33<00:03,  4.06it/s]\u001b[A\n",
            " 91% 140/154 [00:33<00:03,  4.09it/s]\u001b[A\n",
            " 92% 141/154 [00:34<00:03,  4.10it/s]\u001b[A\n",
            " 92% 142/154 [00:34<00:02,  4.10it/s]\u001b[A\n",
            " 93% 143/154 [00:34<00:02,  4.10it/s]\u001b[A\n",
            " 94% 144/154 [00:34<00:02,  4.11it/s]\u001b[A\n",
            " 94% 145/154 [00:35<00:02,  4.11it/s]\u001b[A\n",
            " 95% 146/154 [00:35<00:01,  4.11it/s]\u001b[A\n",
            " 95% 147/154 [00:35<00:01,  4.11it/s]\u001b[A\n",
            " 96% 148/154 [00:35<00:01,  4.11it/s]\u001b[A\n",
            " 97% 149/154 [00:36<00:01,  4.10it/s]\u001b[A\n",
            " 97% 150/154 [00:36<00:00,  4.12it/s]\u001b[A\n",
            " 98% 151/154 [00:36<00:00,  4.11it/s]\u001b[A\n",
            " 99% 152/154 [00:36<00:00,  4.11it/s]\u001b[A\n",
            " 99% 153/154 [00:37<00:00,  4.10it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.8482455611228943, 'eval_runtime': 37.4036, 'eval_samples_per_second': 65.528, 'eval_steps_per_second': 4.117, 'epoch': 1.0}\n",
            "100% 613/613 [07:39<00:00,  1.72it/s]\n",
            "100% 154/154 [00:37<00:00,  4.11it/s]\u001b[A\n",
            "{'train_runtime': 531.9851, 'train_samples_per_second': 18.422, 'train_steps_per_second': 1.152, 'train_loss': 0.8912857702855769, 'epoch': 1.0}\n",
            "100% 613/613 [07:46<00:00,  1.31it/s]\n",
            "\u001b[1;34mwandb\u001b[0m: ğŸš€ View run \u001b[33m./results\u001b[0m at: \u001b[34mhttps://wandb.ai/navashakthi-capgemini/huggingface/runs/v9n7puj9\u001b[0m\n",
            "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20241107_135712-v9n7puj9/logs\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python /content/train.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from fastapi import FastAPI, HTTPException\n",
        "from pydantic import BaseModel\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "import gradio as gr\n",
        "import threading\n",
        "\n",
        "# Initialize FastAPI app\n",
        "app = FastAPI()\n",
        "\n",
        "# Load the model and tokenizer (ensure your model path or model loading code is correct)\n",
        "model_path = '/content/fine-tuned-model'  # Adjust the model path if needed\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "\n",
        "# Define the Pydantic model for input validation\n",
        "class Claim(BaseModel):\n",
        "    text: str\n",
        "\n",
        "# FastAPI endpoint to get prediction\n",
        "@app.post(\"/claim/v1/predict\")\n",
        "async def predict_claim(claim: Claim):\n",
        "    try:\n",
        "        # Tokenize input text\n",
        "        inputs = tokenizer(claim.text, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "            logits = outputs.logits\n",
        "            predicted_label = torch.argmax(logits, dim=1).item()\n",
        "        return {\"claim\": claim.text, \"veracity\": predicted_label}\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=str(e))\n",
        "\n",
        "# Define the Gradio interface function\n",
        "def gradio_predict(text):\n",
        "    try:\n",
        "        inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "            logits = outputs.logits\n",
        "            predicted_label = torch.argmax(logits, dim=1).item()\n",
        "        return f\"Label {predicted_label}\"  # Returns the label directly as 0, 1, 2, or 3\n",
        "    except Exception as e:\n",
        "        return f\"Error: {e}\"\n",
        "\n",
        "# Set up Gradio interface\n",
        "gr_interface = gr.Interface(fn=gradio_predict, inputs=\"text\", outputs=\"text\",\n",
        "                            title=\"Claim Veracity Predictor\",\n",
        "                            description=\"Enter a claim to predict its veracity.\")\n",
        "\n",
        "# Run Gradio in a separate thread\n",
        "def run_gradio():\n",
        "    gr_interface.launch(server_name=\"0.0.0.0\", server_port=7865)\n",
        "\n",
        "gradio_thread = threading.Thread(target=run_gradio)\n",
        "gradio_thread.start()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    import uvicorn\n",
        "    uvicorn.run(\"main:app\", host=\"0.0.0.0\", port=8000, reload=True)\n"
      ],
      "metadata": {
        "id": "fXplbQGkA5v7",
        "outputId": "3e1ff86a-305b-4c1a-c8b5-7f57553bab4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://05b00a0a46d2c99cd5.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://05b00a0a46d2c99cd5.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/serve.py"
      ],
      "metadata": {
        "id": "lOhbBpFZ9MLd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7a5890a-5df0-4fe9-e284-225b8ffc4c9d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32mINFO\u001b[0m:     Will watch for changes in these directories: ['/content']\n",
            "* Running on local URL:  http://0.0.0.0:7865\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n",
            "Exception in thread Thread-4 (run_gradio):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/content/serve.py\", line 54, in run_gradio\n",
            "    gr_interface.launch(server_name=\"0.0.0.0\", server_port=7865)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 2482, in launch\n",
            "    ) = http_server.start_server(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/http_server.py\", line 156, in start_server\n",
            "    raise OSError(\n",
            "OSError: Cannot find empty port in range: 7865-7865. You can specify a different port by setting the GRADIO_SERVER_PORT environment variable or passing the `server_port` parameter to `launch()`.\n",
            "\u001b[31mERROR\u001b[0m:    Error loading ASGI app. Could not import module \"main\".\n",
            "\u001b[33mWARNING\u001b[0m:  WatchFiles detected changes in 'serve.py'. Reloading...\n",
            "\u001b[33mWARNING\u001b[0m:  WatchFiles detected changes in 'serve.py'. Reloading...\n",
            "\u001b[31mERROR\u001b[0m:    Error loading ASGI app. Could not import module \"main\".\n",
            "Exception in thread Thread-4 (run_gradio):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/content/serve.py\", line 53, in run_gradio\n",
            "    gr_interface.launch(server_name=\"0.0.0.0\", server_port=7865)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 2482, in launch\n",
            "    ) = http_server.start_server(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/http_server.py\", line 156, in start_server\n",
            "    raise OSError(\n",
            "OSError: Cannot find empty port in range: 7865-7865. You can specify a different port by setting the GRADIO_SERVER_PORT environment variable or passing the `server_port` parameter to `launch()`.\n",
            "^C\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}